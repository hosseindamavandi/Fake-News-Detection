{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "time: 156 ms (started: 2023-07-25 10:54:53 +03:00)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q ipython-autotime\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%timeit\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms (started: 2023-07-25 10:54:53 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from Utils import *\n",
    "from preprocess import *\n",
    "from models import ANN, CNN1D, BILSTM\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 140 ms (started: 2023-07-25 10:54:53 +03:00)\n"
     ]
    }
   ],
   "source": [
    "loaded_data = np.load(\"cleaned-dataset\\data_npy.npy\")\n",
    "X_train, X_test, y_train, y_test = split_data(loaded_data, ratio=0.70, seed=42)\n",
    "\n",
    "training_dataset = TextDataset(X_train, y_train)\n",
    "testing_dataset = TextDataset(X_test, y_test)\n",
    "train_loader = DataLoader(dataset=training_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(dataset=training_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 156 ms (started: 2023-07-25 10:54:54 +03:00)\n"
     ]
    }
   ],
   "source": [
    "def acc_func(y_true, y_pred):\n",
    "    y_pred = torch.round(y_pred)\n",
    "    return (y_true == y_pred).sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 100]),\n",
       " torch.Size([128, 1, 100]),\n",
       " torch.Size([128, 100, 1]),\n",
       " torch.Size([1, 128, 100]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms (started: 2023-07-25 10:54:54 +03:00)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, x.unsqueeze(1).shape, x.unsqueeze(-1).shape, x.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms (started: 2023-07-25 10:54:54 +03:00)\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = x.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms (started: 2023-07-25 10:54:54 +03:00)\n"
     ]
    }
   ],
   "source": [
    "#* GLOABL VARIABLES\n",
    "EPOCHS = 150\n",
    "LEARNING_RATE = 0.0001\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "model = CNN1D().to(DEVICE)\n",
    "\n",
    "#* LSTM \n",
    "INPUT_SIZE = x.shape[1]\n",
    "HIDDEN_STATE = 64\n",
    "NUM_LAYERS = 4\n",
    "NUM_CLASSES = 1 #* binary classification\n",
    "\n",
    "# model = BILSTM(INPUT_SIZE, HIDDEN_STATE, NUM_LAYERS, NUM_CLASSES, bidirection=True).to(DEVICE)\n",
    "\n",
    "\n",
    "loss = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5078125\n",
      "0.46875\n",
      "0.4921875\n",
      "0.46875\n",
      "0.4921875\n",
      "0.515625\n",
      "0.5078125\n",
      "0.4921875\n",
      "0.5234375\n",
      "0.53125\n",
      "time: 250 ms (started: 2023-07-25 10:54:54 +03:00)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "accum_acc = 0\n",
    "for i in range(10):\n",
    "    x, y = next(iter(train_loader))\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    model.train()\n",
    "    preds = model(x).squeeze()\n",
    "    lossval= loss(preds, y)\n",
    "    optimizer.zero_grad()\n",
    "    lossval.backward()\n",
    "    optimizer.step()\n",
    "    acc = Accuracy(task='binary').to(DEVICE)\n",
    "    print(acc(preds, y).item())\n",
    "    # model.train()\n",
    "    accum_acc += acc(preds, y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 172 ms (started: 2023-07-25 10:54:55 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# torch.save(ann.state_dict(), \"model.pth\")\n",
    "# ann_loaded = ANN().to(DEVICE)\n",
    "# ann_loaded.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model\n",
      "Epoch 0 | Train Loss: 0.27408\n",
      "Epoch 0 | Train Acc: 83.86%\n",
      "Epoch 0 | Test Loss: 0.13298\n",
      "Epoch 0 | Test Acc: 95.21%\n",
      "Test loss decreased from inf to 0.13298 saving new best model\n",
      "--------------------------------------------------\n",
      "Epoch 1 | Train Loss: 0.26658\n",
      "Epoch 1 | Train Acc: 84.02%\n",
      "Epoch 1 | Test Loss: 0.13353\n",
      "Epoch 1 | Test Acc: 95.18%\n",
      "--------------------------------------------------\n",
      "Epoch 2 | Train Loss: 0.26785\n",
      "Epoch 2 | Train Acc: 84.26%\n",
      "Epoch 2 | Test Loss: 0.13254\n",
      "Epoch 2 | Test Acc: 95.09%\n",
      "Test loss decreased from 0.13298 to 0.13254 saving new best model\n",
      "--------------------------------------------------\n",
      "Epoch 3 | Train Loss: 0.26810\n",
      "Epoch 3 | Train Acc: 84.19%\n",
      "Epoch 3 | Test Loss: 0.13205\n",
      "Epoch 3 | Test Acc: 95.13%\n",
      "Test loss decreased from 0.13254 to 0.13205 saving new best model\n",
      "--------------------------------------------------\n",
      "Epoch 4 | Train Loss: 0.26641\n",
      "Epoch 4 | Train Acc: 84.34%\n",
      "Epoch 4 | Test Loss: 0.13080\n",
      "Epoch 4 | Test Acc: 95.22%\n",
      "Test loss decreased from 0.13205 to 0.13080 saving new best model\n",
      "--------------------------------------------------\n",
      "Epoch 5 | Train Loss: 0.27033\n",
      "Epoch 5 | Train Acc: 84.47%\n",
      "Epoch 5 | Test Loss: 0.13181\n",
      "Epoch 5 | Test Acc: 95.28%\n",
      "--------------------------------------------------\n",
      "Epoch 6 | Train Loss: 0.26974\n",
      "Epoch 6 | Train Acc: 83.86%\n",
      "Epoch 6 | Test Loss: 0.13123\n",
      "Epoch 6 | Test Acc: 95.15%\n",
      "--------------------------------------------------\n",
      "Epoch 7 | Train Loss: 0.27042\n",
      "Epoch 7 | Train Acc: 83.85%\n",
      "Epoch 7 | Test Loss: 0.13169\n",
      "Epoch 7 | Test Acc: 95.24%\n",
      "--------------------------------------------------\n",
      "Epoch 8 | Train Loss: 0.26096\n",
      "Epoch 8 | Train Acc: 84.67%\n",
      "Epoch 8 | Test Loss: 0.12860\n",
      "Epoch 8 | Test Acc: 95.24%\n",
      "Test loss decreased from 0.13080 to 0.12860 saving new best model\n",
      "--------------------------------------------------\n",
      "Epoch 9 | Train Loss: 0.26662\n",
      "Epoch 9 | Train Acc: 84.25%\n",
      "Epoch 9 | Test Loss: 0.12943\n",
      "Epoch 9 | Test Acc: 95.27%\n",
      "--------------------------------------------------\n",
      "Epoch 10 | Train Loss: 0.26559\n",
      "Epoch 10 | Train Acc: 84.22%\n",
      "Epoch 10 | Test Loss: 0.13077\n",
      "Epoch 10 | Test Acc: 95.13%\n",
      "--------------------------------------------------\n",
      "Epoch 11 | Train Loss: 0.26458\n",
      "Epoch 11 | Train Acc: 84.35%\n",
      "Epoch 11 | Test Loss: 0.12823\n",
      "Epoch 11 | Test Acc: 95.28%\n",
      "Test loss decreased from 0.12860 to 0.12823 saving new best model\n",
      "--------------------------------------------------\n",
      "Epoch 12 | Train Loss: 0.26831\n",
      "Epoch 12 | Train Acc: 84.04%\n",
      "Epoch 12 | Test Loss: 0.13670\n",
      "Epoch 12 | Test Acc: 94.87%\n",
      "--------------------------------------------------\n",
      "Epoch 13 | Train Loss: 0.26807\n",
      "Epoch 13 | Train Acc: 84.24%\n",
      "Epoch 13 | Test Loss: 0.13093\n",
      "Epoch 13 | Test Acc: 95.26%\n",
      "--------------------------------------------------\n",
      "Epoch 14 | Train Loss: 0.26653\n",
      "Epoch 14 | Train Acc: 84.18%\n",
      "Epoch 14 | Test Loss: 0.13109\n",
      "Epoch 14 | Test Acc: 95.14%\n",
      "--------------------------------------------------\n",
      "Interrupted, returning saved history\n",
      "time: 55.2 s (started: 2023-07-25 11:08:29 +03:00)\n"
     ]
    }
   ],
   "source": [
    "history = Training(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    DEVICE,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    print_every=1,\n",
    "    load_saved_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 140 ms (started: 2023-07-24 21:23:44 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# loaded_ann = ANN().to(DEVICE)\n",
    "# loaded_ann.load_state_dict(torch.load(\"ANN_best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Real, with probability: 88.13%'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 954 ms (started: 2023-07-25 10:54:25 +03:00)\n"
     ]
    }
   ],
   "source": [
    "sample = \"The billionaire changed his profile picture to the new logo and added X.com to his Twitter bio.\"\n",
    "path = \"C:\\\\Users\\\\DELL\\\\OneDrive\\\\Desktop\\\\AI projects\\\\Fake-News-Detection\\\\word2vec_model\\\\word2vec.model\"\n",
    "word2vec_model = Load_word2vec(path)\n",
    "\n",
    "from preprocess import *\n",
    "predict(sample, word2vec_model, model, DEVICE)\n",
    "# sample = preprocess_text(sample)\n",
    "# sample = vectorize_text(sample, word2vec_model)\n",
    "# model(torch.tensor(sample).float().to(DEVICE))\n",
    "# print(predict(sample, word2vec_model, loaded_ann, DEVICE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_pred = ann(torch.tensor(X_test).float().to(DEVICE)).to(\"cpu\").detach().numpy().reshape(-1)\n",
    "\n",
    "\n",
    "# Accuracy score\n",
    "print(\"Model accuracy is \",accuracy_score(y_pred,y_test))\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_pred=y_pred,y_true=y_test)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_matrix,annot=True,fmt=\"0.1f\",linewidths=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
