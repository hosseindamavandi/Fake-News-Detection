{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wulUl-0GRyN",
        "outputId": "c8d0c1d5-3159-41f1-e261-4a45ae9d11a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Fake-News-Detection'...\n",
            "remote: Enumerating objects: 434, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 434 (delta 39), reused 49 (delta 21), pack-reused 349\u001b[K\n",
            "Receiving objects: 100% (434/434), 98.52 MiB | 25.07 MiB/s, done.\n",
            "Resolving deltas: 100% (227/227), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hosseindamavandi/Fake-News-Detection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "S5fE2CuVJVPu",
        "outputId": "3ebff247-0e86-4faa-dab1-876cd599238d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Fake-News-Detection'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/Fake-News-Detection')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bU4HCpynJdt9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Utils import *\n",
        "from models import *\n",
        "from plots import *\n",
        "from preprocess import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-zBP7Y83JgyM"
      },
      "outputs": [],
      "source": [
        "loaded_data = np.load(r\"cleaned-dataset/data_npy.npy\")\n",
        "X_train, X_test, y_train, y_test = split_data(loaded_data, ratio=0.70, seed=42)\n",
        "\n",
        "training_dataset = TextDataset(X_train, y_train)\n",
        "testing_dataset = TextDataset(X_test, y_test)\n",
        "train_loader = DataLoader(dataset=training_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=training_dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0s_WXt5EKZvs"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 300\n",
        "LEARNING_RATE = 3e-4\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRl3lCylKt2U",
        "outputId": "ed321e5a-9261-4330-d4b2-df03b2b21684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train Loss: 0.47422\n",
            "Epoch 0 | Train Acc: 86.81%\n",
            "Epoch 0 | Test Loss: 0.30291\n",
            "Epoch 0 | Test Acc: 89.30%\n",
            "Test loss decreased to 0.30291 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 5 | Train Loss: 0.17439\n",
            "Epoch 5 | Train Acc: 93.07%\n",
            "Epoch 5 | Test Loss: 0.16051\n",
            "Epoch 5 | Test Acc: 93.21%\n",
            "Test loss decreased from 0.16694 to 0.16051 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 10 | Train Loss: 0.14083\n",
            "Epoch 10 | Train Acc: 94.56%\n",
            "Epoch 10 | Test Loss: 0.12787\n",
            "Epoch 10 | Test Acc: 94.97%\n",
            "--------------------------------------------------\n",
            "Epoch 15 | Train Loss: 0.11337\n",
            "Epoch 15 | Train Acc: 95.53%\n",
            "Epoch 15 | Test Loss: 0.09353\n",
            "Epoch 15 | Test Acc: 96.43%\n",
            "Test loss decreased from 0.09979 to 0.09353 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 20 | Train Loss: 0.08908\n",
            "Epoch 20 | Train Acc: 96.55%\n",
            "Epoch 20 | Test Loss: 0.08114\n",
            "Epoch 20 | Test Acc: 96.73%\n",
            "--------------------------------------------------\n",
            "Epoch 25 | Train Loss: 0.07407\n",
            "Epoch 25 | Train Acc: 97.00%\n",
            "Epoch 25 | Test Loss: 0.04781\n",
            "Epoch 25 | Test Acc: 98.24%\n",
            "Test loss decreased from 0.05488 to 0.04781 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 30 | Train Loss: 0.06182\n",
            "Epoch 30 | Train Acc: 97.64%\n",
            "Epoch 30 | Test Loss: 0.03567\n",
            "Epoch 30 | Test Acc: 98.78%\n",
            "Test loss decreased from 0.03764 to 0.03567 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 35 | Train Loss: 0.04592\n",
            "Epoch 35 | Train Acc: 98.18%\n",
            "Epoch 35 | Test Loss: 0.02509\n",
            "Epoch 35 | Test Acc: 98.93%\n",
            "Test loss decreased from 0.02669 to 0.02509 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 40 | Train Loss: 0.03887\n",
            "Epoch 40 | Train Acc: 98.53%\n",
            "Epoch 40 | Test Loss: 0.01839\n",
            "Epoch 40 | Test Acc: 99.41%\n",
            "--------------------------------------------------\n",
            "Epoch 45 | Train Loss: 0.02548\n",
            "Epoch 45 | Train Acc: 99.06%\n",
            "Epoch 45 | Test Loss: 0.00677\n",
            "Epoch 45 | Test Acc: 99.84%\n",
            "Test loss decreased from 0.00816 to 0.00677 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 50 | Train Loss: 0.02524\n",
            "Epoch 50 | Train Acc: 99.00%\n",
            "Epoch 50 | Test Loss: 0.01055\n",
            "Epoch 50 | Test Acc: 99.82%\n",
            "--------------------------------------------------\n",
            "Epoch 55 | Train Loss: 0.02406\n",
            "Epoch 55 | Train Acc: 99.12%\n",
            "Epoch 55 | Test Loss: 0.00558\n",
            "Epoch 55 | Test Acc: 99.89%\n",
            "--------------------------------------------------\n",
            "Epoch 60 | Train Loss: 0.01772\n",
            "Epoch 60 | Train Acc: 99.35%\n",
            "Epoch 60 | Test Loss: 0.00399\n",
            "Epoch 60 | Test Acc: 99.96%\n",
            "Test loss decreased from 0.00452 to 0.00399 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 65 | Train Loss: 0.01319\n",
            "Epoch 65 | Train Acc: 99.51%\n",
            "Epoch 65 | Test Loss: 0.00213\n",
            "Epoch 65 | Test Acc: 99.97%\n",
            "Test loss decreased from 0.00240 to 0.00213 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 70 | Train Loss: 0.01274\n",
            "Epoch 70 | Train Acc: 99.52%\n",
            "Epoch 70 | Test Loss: 0.00160\n",
            "Epoch 70 | Test Acc: 99.97%\n",
            "Test loss decreased from 0.00189 to 0.00160 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 75 | Train Loss: 0.01620\n",
            "Epoch 75 | Train Acc: 99.47%\n",
            "Epoch 75 | Test Loss: 0.00330\n",
            "Epoch 75 | Test Acc: 99.93%\n",
            "--------------------------------------------------\n",
            "Epoch 80 | Train Loss: 0.00888\n",
            "Epoch 80 | Train Acc: 99.74%\n",
            "Epoch 80 | Test Loss: 0.00110\n",
            "Epoch 80 | Test Acc: 100.00%\n",
            "Test loss decreased from 0.00128 to 0.00110 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 85 | Train Loss: 0.01317\n",
            "Epoch 85 | Train Acc: 99.56%\n",
            "Epoch 85 | Test Loss: 0.00194\n",
            "Epoch 85 | Test Acc: 99.98%\n",
            "--------------------------------------------------\n",
            "Epoch 90 | Train Loss: 0.01115\n",
            "Epoch 90 | Train Acc: 99.62%\n",
            "Epoch 90 | Test Loss: 0.00083\n",
            "Epoch 90 | Test Acc: 99.99%\n",
            "Test loss decreased from 0.00095 to 0.00083 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 95 | Train Loss: 0.01015\n",
            "Epoch 95 | Train Acc: 99.67%\n",
            "Epoch 95 | Test Loss: 0.00296\n",
            "Epoch 95 | Test Acc: 99.92%\n",
            "--------------------------------------------------\n",
            "Epoch 100 | Train Loss: 0.01233\n",
            "Epoch 100 | Train Acc: 99.62%\n",
            "Epoch 100 | Test Loss: 0.00164\n",
            "Epoch 100 | Test Acc: 99.98%\n",
            "--------------------------------------------------\n",
            "Epoch 105 | Train Loss: 0.00596\n",
            "Epoch 105 | Train Acc: 99.80%\n",
            "Epoch 105 | Test Loss: 0.00026\n",
            "Epoch 105 | Test Acc: 100.00%\n",
            "Test loss decreased from 0.00031 to 0.00026 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 110 | Train Loss: 0.00716\n",
            "Epoch 110 | Train Acc: 99.75%\n",
            "Epoch 110 | Test Loss: 0.00024\n",
            "Epoch 110 | Test Acc: 100.00%\n",
            "Test loss decreased from 0.00026 to 0.00024 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 115 | Train Loss: 0.00581\n",
            "Epoch 115 | Train Acc: 99.80%\n",
            "Epoch 115 | Test Loss: 0.00034\n",
            "Epoch 115 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 120 | Train Loss: 0.00710\n",
            "Epoch 120 | Train Acc: 99.77%\n",
            "Epoch 120 | Test Loss: 0.00043\n",
            "Epoch 120 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 125 | Train Loss: 0.00972\n",
            "Epoch 125 | Train Acc: 99.68%\n",
            "Epoch 125 | Test Loss: 0.00116\n",
            "Epoch 125 | Test Acc: 99.98%\n",
            "--------------------------------------------------\n",
            "Epoch 130 | Train Loss: 0.00837\n",
            "Epoch 130 | Train Acc: 99.70%\n",
            "Epoch 130 | Test Loss: 0.00057\n",
            "Epoch 130 | Test Acc: 99.99%\n",
            "--------------------------------------------------\n",
            "Epoch 135 | Train Loss: 0.00641\n",
            "Epoch 135 | Train Acc: 99.78%\n",
            "Epoch 135 | Test Loss: 0.00144\n",
            "Epoch 135 | Test Acc: 99.98%\n",
            "--------------------------------------------------\n",
            "Epoch 140 | Train Loss: 0.00950\n",
            "Epoch 140 | Train Acc: 99.69%\n",
            "Epoch 140 | Test Loss: 0.00083\n",
            "Epoch 140 | Test Acc: 99.99%\n",
            "--------------------------------------------------\n",
            "Epoch 145 | Train Loss: 0.00693\n",
            "Epoch 145 | Train Acc: 99.79%\n",
            "Epoch 145 | Test Loss: 0.00034\n",
            "Epoch 145 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 150 | Train Loss: 0.00595\n",
            "Epoch 150 | Train Acc: 99.81%\n",
            "Epoch 150 | Test Loss: 0.00059\n",
            "Epoch 150 | Test Acc: 99.99%\n",
            "--------------------------------------------------\n",
            "Epoch 155 | Train Loss: 0.00598\n",
            "Epoch 155 | Train Acc: 99.82%\n",
            "Epoch 155 | Test Loss: 0.00054\n",
            "Epoch 155 | Test Acc: 99.99%\n",
            "--------------------------------------------------\n",
            "Epoch 160 | Train Loss: 0.00330\n",
            "Epoch 160 | Train Acc: 99.90%\n",
            "Epoch 160 | Test Loss: 0.00016\n",
            "Epoch 160 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 165 | Train Loss: 0.00467\n",
            "Epoch 165 | Train Acc: 99.85%\n",
            "Epoch 165 | Test Loss: 0.00057\n",
            "Epoch 165 | Test Acc: 99.99%\n",
            "--------------------------------------------------\n",
            "Epoch 170 | Train Loss: 0.00472\n",
            "Epoch 170 | Train Acc: 99.86%\n",
            "Epoch 170 | Test Loss: 0.00028\n",
            "Epoch 170 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 175 | Train Loss: 0.00733\n",
            "Epoch 175 | Train Acc: 99.78%\n",
            "Epoch 175 | Test Loss: 0.00030\n",
            "Epoch 175 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 180 | Train Loss: 0.00334\n",
            "Epoch 180 | Train Acc: 99.88%\n",
            "Epoch 180 | Test Loss: 0.00011\n",
            "Epoch 180 | Test Acc: 100.00%\n",
            "Test loss decreased from 0.00013 to 0.00011 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 185 | Train Loss: 0.00593\n",
            "Epoch 185 | Train Acc: 99.78%\n",
            "Epoch 185 | Test Loss: 0.00020\n",
            "Epoch 185 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 190 | Train Loss: 0.00363\n",
            "Epoch 190 | Train Acc: 99.88%\n",
            "Epoch 190 | Test Loss: 0.00009\n",
            "Epoch 190 | Test Acc: 100.00%\n",
            "Test loss decreased from 0.00011 to 0.00009 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 195 | Train Loss: 0.00430\n",
            "Epoch 195 | Train Acc: 99.86%\n",
            "Epoch 195 | Test Loss: 0.00020\n",
            "Epoch 195 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 200 | Train Loss: 0.00316\n",
            "Epoch 200 | Train Acc: 99.90%\n",
            "Epoch 200 | Test Loss: 0.00007\n",
            "Epoch 200 | Test Acc: 100.00%\n",
            "Test loss decreased from 0.00009 to 0.00007 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 205 | Train Loss: 0.00256\n",
            "Epoch 205 | Train Acc: 99.92%\n",
            "Epoch 205 | Test Loss: 0.00004\n",
            "Epoch 205 | Test Acc: 100.00%\n",
            "Test loss decreased from 0.00007 to 0.00004 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 210 | Train Loss: 0.00525\n",
            "Epoch 210 | Train Acc: 99.80%\n",
            "Epoch 210 | Test Loss: 0.00015\n",
            "Epoch 210 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 215 | Train Loss: 0.00249\n",
            "Epoch 215 | Train Acc: 99.92%\n",
            "Epoch 215 | Test Loss: 0.00007\n",
            "Epoch 215 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 220 | Train Loss: 0.00456\n",
            "Epoch 220 | Train Acc: 99.85%\n",
            "Epoch 220 | Test Loss: 0.00048\n",
            "Epoch 220 | Test Acc: 99.99%\n",
            "--------------------------------------------------\n",
            "Epoch 225 | Train Loss: 0.00365\n",
            "Epoch 225 | Train Acc: 99.86%\n",
            "Epoch 225 | Test Loss: 0.00012\n",
            "Epoch 225 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 230 | Train Loss: 0.00446\n",
            "Epoch 230 | Train Acc: 99.87%\n",
            "Epoch 230 | Test Loss: 0.00019\n",
            "Epoch 230 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 235 | Train Loss: 0.00278\n",
            "Epoch 235 | Train Acc: 99.92%\n",
            "Epoch 235 | Test Loss: 0.00058\n",
            "Epoch 235 | Test Acc: 99.98%\n",
            "--------------------------------------------------\n",
            "Epoch 240 | Train Loss: 0.00381\n",
            "Epoch 240 | Train Acc: 99.87%\n",
            "Epoch 240 | Test Loss: 0.00009\n",
            "Epoch 240 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 245 | Train Loss: 0.00288\n",
            "Epoch 245 | Train Acc: 99.91%\n",
            "Epoch 245 | Test Loss: 0.00009\n",
            "Epoch 245 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 250 | Train Loss: 0.00422\n",
            "Epoch 250 | Train Acc: 99.85%\n",
            "Epoch 250 | Test Loss: 0.00013\n",
            "Epoch 250 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 255 | Train Loss: 0.00277\n",
            "Epoch 255 | Train Acc: 99.92%\n",
            "Epoch 255 | Test Loss: 0.00007\n",
            "Epoch 255 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 260 | Train Loss: 0.00448\n",
            "Epoch 260 | Train Acc: 99.86%\n",
            "Epoch 260 | Test Loss: 0.00015\n",
            "Epoch 260 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 265 | Train Loss: 0.00248\n",
            "Epoch 265 | Train Acc: 99.92%\n",
            "Epoch 265 | Test Loss: 0.00006\n",
            "Epoch 265 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 270 | Train Loss: 0.00547\n",
            "Epoch 270 | Train Acc: 99.86%\n",
            "Epoch 270 | Test Loss: 0.00023\n",
            "Epoch 270 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 275 | Train Loss: 0.00537\n",
            "Epoch 275 | Train Acc: 99.85%\n",
            "Epoch 275 | Test Loss: 0.00038\n",
            "Epoch 275 | Test Acc: 99.99%\n",
            "--------------------------------------------------\n",
            "Epoch 280 | Train Loss: 0.00406\n",
            "Epoch 280 | Train Acc: 99.88%\n",
            "Epoch 280 | Test Loss: 0.00040\n",
            "Epoch 280 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 285 | Train Loss: 0.00407\n",
            "Epoch 285 | Train Acc: 99.86%\n",
            "Epoch 285 | Test Loss: 0.00015\n",
            "Epoch 285 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 290 | Train Loss: 0.00239\n",
            "Epoch 290 | Train Acc: 99.93%\n",
            "Epoch 290 | Test Loss: 0.00016\n",
            "Epoch 290 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n",
            "Epoch 295 | Train Loss: 0.00332\n",
            "Epoch 295 | Train Acc: 99.89%\n",
            "Epoch 295 | Test Loss: 0.00005\n",
            "Epoch 295 | Test Acc: 100.00%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = ANN().to(DEVICE)\n",
        "loss = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "history = Training(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    EPOCHS,\n",
        "    DEVICE,\n",
        "    loss,\n",
        "    optimizer,\n",
        "    print_every=5,\n",
        "    load_saved_model=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fneqEcJ4MgbT"
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame(history)\n",
        "history_df.to_csv(\"ANN_history.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "facUacHnOTRa",
        "outputId": "969249a2-6c11-4ce9-9952-2a6d8c8bbdfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train Loss: 0.58354\n",
            "Epoch 0 | Train Acc: 74.09%\n",
            "Epoch 0 | Test Loss: 0.46335\n",
            "Epoch 0 | Test Acc: 91.25%\n",
            "Test loss decreased to 0.46335 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 5 | Train Loss: 0.32636\n",
            "Epoch 5 | Train Acc: 81.62%\n",
            "Epoch 5 | Test Loss: 0.21458\n",
            "Epoch 5 | Test Acc: 91.37%\n",
            "Test loss decreased from 0.23253 to 0.21458 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 10 | Train Loss: 0.31581\n",
            "Epoch 10 | Train Acc: 82.21%\n",
            "Epoch 10 | Test Loss: 0.19403\n",
            "Epoch 10 | Test Acc: 92.29%\n",
            "Test loss decreased from 0.20315 to 0.19403 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 15 | Train Loss: 0.30779\n",
            "Epoch 15 | Train Acc: 82.15%\n",
            "Epoch 15 | Test Loss: 0.18457\n",
            "Epoch 15 | Test Acc: 92.68%\n",
            "Test loss decreased from 0.18488 to 0.18457 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 20 | Train Loss: 0.29612\n",
            "Epoch 20 | Train Acc: 82.87%\n",
            "Epoch 20 | Test Loss: 0.17418\n",
            "Epoch 20 | Test Acc: 93.31%\n",
            "Test loss decreased from 0.17630 to 0.17418 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 25 | Train Loss: 0.29131\n",
            "Epoch 25 | Train Acc: 83.02%\n",
            "Epoch 25 | Test Loss: 0.16293\n",
            "Epoch 25 | Test Acc: 93.74%\n",
            "Test loss decreased from 0.16892 to 0.16293 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 30 | Train Loss: 0.28896\n",
            "Epoch 30 | Train Acc: 83.22%\n",
            "Epoch 30 | Test Loss: 0.15922\n",
            "Epoch 30 | Test Acc: 93.78%\n",
            "Test loss decreased from 0.16025 to 0.15922 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 35 | Train Loss: 0.28275\n",
            "Epoch 35 | Train Acc: 83.54%\n",
            "Epoch 35 | Test Loss: 0.15411\n",
            "Epoch 35 | Test Acc: 93.56%\n",
            "--------------------------------------------------\n",
            "Epoch 40 | Train Loss: 0.27494\n",
            "Epoch 40 | Train Acc: 83.86%\n",
            "Epoch 40 | Test Loss: 0.14337\n",
            "Epoch 40 | Test Acc: 94.68%\n",
            "Test loss decreased from 0.14530 to 0.14337 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 45 | Train Loss: 0.27639\n",
            "Epoch 45 | Train Acc: 83.69%\n",
            "Epoch 45 | Test Loss: 0.13863\n",
            "Epoch 45 | Test Acc: 94.97%\n",
            "--------------------------------------------------\n",
            "Epoch 50 | Train Loss: 0.26964\n",
            "Epoch 50 | Train Acc: 83.98%\n",
            "Epoch 50 | Test Loss: 0.13357\n",
            "Epoch 50 | Test Acc: 95.19%\n",
            "--------------------------------------------------\n",
            "Epoch 55 | Train Loss: 0.26348\n",
            "Epoch 55 | Train Acc: 84.12%\n",
            "Epoch 55 | Test Loss: 0.13058\n",
            "Epoch 55 | Test Acc: 94.71%\n",
            "--------------------------------------------------\n",
            "Epoch 60 | Train Loss: 0.26078\n",
            "Epoch 60 | Train Acc: 84.65%\n",
            "Epoch 60 | Test Loss: 0.12154\n",
            "Epoch 60 | Test Acc: 95.79%\n",
            "Test loss decreased from 0.12260 to 0.12154 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 65 | Train Loss: 0.26075\n",
            "Epoch 65 | Train Acc: 84.46%\n",
            "Epoch 65 | Test Loss: 0.11774\n",
            "Epoch 65 | Test Acc: 95.81%\n",
            "--------------------------------------------------\n",
            "Epoch 70 | Train Loss: 0.25693\n",
            "Epoch 70 | Train Acc: 84.78%\n",
            "Epoch 70 | Test Loss: 0.11481\n",
            "Epoch 70 | Test Acc: 96.01%\n",
            "Test loss decreased from 0.11638 to 0.11481 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 75 | Train Loss: 0.25628\n",
            "Epoch 75 | Train Acc: 84.82%\n",
            "Epoch 75 | Test Loss: 0.11610\n",
            "Epoch 75 | Test Acc: 96.08%\n",
            "--------------------------------------------------\n",
            "Epoch 80 | Train Loss: 0.25088\n",
            "Epoch 80 | Train Acc: 84.94%\n",
            "Epoch 80 | Test Loss: 0.11268\n",
            "Epoch 80 | Test Acc: 95.27%\n",
            "--------------------------------------------------\n",
            "Epoch 85 | Train Loss: 0.25526\n",
            "Epoch 85 | Train Acc: 84.64%\n",
            "Epoch 85 | Test Loss: 0.10588\n",
            "Epoch 85 | Test Acc: 96.20%\n",
            "--------------------------------------------------\n",
            "Epoch 90 | Train Loss: 0.24763\n",
            "Epoch 90 | Train Acc: 85.04%\n",
            "Epoch 90 | Test Loss: 0.10948\n",
            "Epoch 90 | Test Acc: 95.31%\n",
            "--------------------------------------------------\n",
            "Epoch 95 | Train Loss: 0.24693\n",
            "Epoch 95 | Train Acc: 84.93%\n",
            "Epoch 95 | Test Loss: 0.09775\n",
            "Epoch 95 | Test Acc: 96.56%\n",
            "--------------------------------------------------\n",
            "Epoch 100 | Train Loss: 0.24621\n",
            "Epoch 100 | Train Acc: 85.06%\n",
            "Epoch 100 | Test Loss: 0.09463\n",
            "Epoch 100 | Test Acc: 96.64%\n",
            "--------------------------------------------------\n",
            "Epoch 105 | Train Loss: 0.24479\n",
            "Epoch 105 | Train Acc: 85.26%\n",
            "Epoch 105 | Test Loss: 0.09915\n",
            "Epoch 105 | Test Acc: 96.67%\n",
            "--------------------------------------------------\n",
            "Epoch 110 | Train Loss: 0.24097\n",
            "Epoch 110 | Train Acc: 85.37%\n",
            "Epoch 110 | Test Loss: 0.09194\n",
            "Epoch 110 | Test Acc: 96.37%\n",
            "Test loss decreased from 0.09282 to 0.09194 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 115 | Train Loss: 0.23636\n",
            "Epoch 115 | Train Acc: 85.66%\n",
            "Epoch 115 | Test Loss: 0.08918\n",
            "Epoch 115 | Test Acc: 96.81%\n",
            "Test loss decreased from 0.08958 to 0.08918 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 120 | Train Loss: 0.23286\n",
            "Epoch 120 | Train Acc: 85.61%\n",
            "Epoch 120 | Test Loss: 0.09108\n",
            "Epoch 120 | Test Acc: 97.03%\n",
            "--------------------------------------------------\n",
            "Epoch 125 | Train Loss: 0.24023\n",
            "Epoch 125 | Train Acc: 85.55%\n",
            "Epoch 125 | Test Loss: 0.08480\n",
            "Epoch 125 | Test Acc: 96.96%\n",
            "--------------------------------------------------\n",
            "Epoch 130 | Train Loss: 0.23530\n",
            "Epoch 130 | Train Acc: 85.60%\n",
            "Epoch 130 | Test Loss: 0.08259\n",
            "Epoch 130 | Test Acc: 97.42%\n",
            "--------------------------------------------------\n",
            "Epoch 135 | Train Loss: 0.23442\n",
            "Epoch 135 | Train Acc: 85.65%\n",
            "Epoch 135 | Test Loss: 0.07908\n",
            "Epoch 135 | Test Acc: 97.38%\n",
            "Test loss decreased from 0.07923 to 0.07908 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 140 | Train Loss: 0.23365\n",
            "Epoch 140 | Train Acc: 85.74%\n",
            "Epoch 140 | Test Loss: 0.08236\n",
            "Epoch 140 | Test Acc: 97.16%\n",
            "--------------------------------------------------\n",
            "Epoch 145 | Train Loss: 0.22844\n",
            "Epoch 145 | Train Acc: 85.90%\n",
            "Epoch 145 | Test Loss: 0.07469\n",
            "Epoch 145 | Test Acc: 97.69%\n",
            "Test loss decreased from 0.07488 to 0.07469 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 150 | Train Loss: 0.22517\n",
            "Epoch 150 | Train Acc: 86.31%\n",
            "Epoch 150 | Test Loss: 0.07182\n",
            "Epoch 150 | Test Acc: 97.75%\n",
            "Test loss decreased from 0.07469 to 0.07182 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 155 | Train Loss: 0.23051\n",
            "Epoch 155 | Train Acc: 85.79%\n",
            "Epoch 155 | Test Loss: 0.07855\n",
            "Epoch 155 | Test Acc: 97.66%\n",
            "--------------------------------------------------\n",
            "Epoch 160 | Train Loss: 0.22579\n",
            "Epoch 160 | Train Acc: 86.10%\n",
            "Epoch 160 | Test Loss: 0.07457\n",
            "Epoch 160 | Test Acc: 97.04%\n",
            "--------------------------------------------------\n",
            "Epoch 165 | Train Loss: 0.22702\n",
            "Epoch 165 | Train Acc: 85.88%\n",
            "Epoch 165 | Test Loss: 0.07059\n",
            "Epoch 165 | Test Acc: 97.70%\n",
            "Test loss decreased from 0.07176 to 0.07059 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 170 | Train Loss: 0.22061\n",
            "Epoch 170 | Train Acc: 86.38%\n",
            "Epoch 170 | Test Loss: 0.07170\n",
            "Epoch 170 | Test Acc: 96.96%\n",
            "--------------------------------------------------\n",
            "Epoch 175 | Train Loss: 0.21876\n",
            "Epoch 175 | Train Acc: 86.60%\n",
            "Epoch 175 | Test Loss: 0.06609\n",
            "Epoch 175 | Test Acc: 97.94%\n",
            "--------------------------------------------------\n",
            "Epoch 180 | Train Loss: 0.22473\n",
            "Epoch 180 | Train Acc: 85.93%\n",
            "Epoch 180 | Test Loss: 0.06900\n",
            "Epoch 180 | Test Acc: 97.16%\n",
            "--------------------------------------------------\n",
            "Epoch 185 | Train Loss: 0.22518\n",
            "Epoch 185 | Train Acc: 85.61%\n",
            "Epoch 185 | Test Loss: 0.06706\n",
            "Epoch 185 | Test Acc: 97.83%\n",
            "--------------------------------------------------\n",
            "Epoch 190 | Train Loss: 0.21974\n",
            "Epoch 190 | Train Acc: 86.24%\n",
            "Epoch 190 | Test Loss: 0.06954\n",
            "Epoch 190 | Test Acc: 96.51%\n",
            "--------------------------------------------------\n",
            "Epoch 195 | Train Loss: 0.21623\n",
            "Epoch 195 | Train Acc: 86.20%\n",
            "Epoch 195 | Test Loss: 0.05701\n",
            "Epoch 195 | Test Acc: 98.23%\n",
            "--------------------------------------------------\n",
            "Epoch 200 | Train Loss: 0.22079\n",
            "Epoch 200 | Train Acc: 86.23%\n",
            "Epoch 200 | Test Loss: 0.05634\n",
            "Epoch 200 | Test Acc: 98.27%\n",
            "Test loss decreased from 0.05648 to 0.05634 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 205 | Train Loss: 0.21669\n",
            "Epoch 205 | Train Acc: 86.50%\n",
            "Epoch 205 | Test Loss: 0.05562\n",
            "Epoch 205 | Test Acc: 98.14%\n",
            "--------------------------------------------------\n",
            "Epoch 210 | Train Loss: 0.21130\n",
            "Epoch 210 | Train Acc: 86.69%\n",
            "Epoch 210 | Test Loss: 0.06148\n",
            "Epoch 210 | Test Acc: 98.35%\n",
            "--------------------------------------------------\n",
            "Epoch 215 | Train Loss: 0.21510\n",
            "Epoch 215 | Train Acc: 86.24%\n",
            "Epoch 215 | Test Loss: 0.05428\n",
            "Epoch 215 | Test Acc: 98.50%\n",
            "--------------------------------------------------\n",
            "Epoch 220 | Train Loss: 0.21197\n",
            "Epoch 220 | Train Acc: 86.48%\n",
            "Epoch 220 | Test Loss: 0.06160\n",
            "Epoch 220 | Test Acc: 97.56%\n",
            "--------------------------------------------------\n",
            "Epoch 225 | Train Loss: 0.20740\n",
            "Epoch 225 | Train Acc: 86.41%\n",
            "Epoch 225 | Test Loss: 0.04871\n",
            "Epoch 225 | Test Acc: 98.61%\n",
            "--------------------------------------------------\n",
            "Epoch 230 | Train Loss: 0.21533\n",
            "Epoch 230 | Train Acc: 86.18%\n",
            "Epoch 230 | Test Loss: 0.04991\n",
            "Epoch 230 | Test Acc: 98.34%\n",
            "--------------------------------------------------\n",
            "Epoch 235 | Train Loss: 0.20685\n",
            "Epoch 235 | Train Acc: 86.69%\n",
            "Epoch 235 | Test Loss: 0.05315\n",
            "Epoch 235 | Test Acc: 97.88%\n",
            "--------------------------------------------------\n",
            "Epoch 240 | Train Loss: 0.20897\n",
            "Epoch 240 | Train Acc: 86.58%\n",
            "Epoch 240 | Test Loss: 0.04301\n",
            "Epoch 240 | Test Acc: 98.54%\n",
            "Test loss decreased from 0.04427 to 0.04301 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 245 | Train Loss: 0.20236\n",
            "Epoch 245 | Train Acc: 87.05%\n",
            "Epoch 245 | Test Loss: 0.04646\n",
            "Epoch 245 | Test Acc: 98.06%\n",
            "--------------------------------------------------\n",
            "Epoch 250 | Train Loss: 0.20453\n",
            "Epoch 250 | Train Acc: 86.79%\n",
            "Epoch 250 | Test Loss: 0.05397\n",
            "Epoch 250 | Test Acc: 97.13%\n",
            "--------------------------------------------------\n",
            "Epoch 255 | Train Loss: 0.20428\n",
            "Epoch 255 | Train Acc: 86.69%\n",
            "Epoch 255 | Test Loss: 0.05201\n",
            "Epoch 255 | Test Acc: 98.28%\n",
            "--------------------------------------------------\n",
            "Epoch 260 | Train Loss: 0.20376\n",
            "Epoch 260 | Train Acc: 86.51%\n",
            "Epoch 260 | Test Loss: 0.04875\n",
            "Epoch 260 | Test Acc: 98.49%\n",
            "--------------------------------------------------\n",
            "Epoch 265 | Train Loss: 0.20793\n",
            "Epoch 265 | Train Acc: 86.30%\n",
            "Epoch 265 | Test Loss: 0.05780\n",
            "Epoch 265 | Test Acc: 98.08%\n",
            "--------------------------------------------------\n",
            "Epoch 270 | Train Loss: 0.20091\n",
            "Epoch 270 | Train Acc: 87.03%\n",
            "Epoch 270 | Test Loss: 0.04038\n",
            "Epoch 270 | Test Acc: 98.92%\n",
            "--------------------------------------------------\n",
            "Epoch 275 | Train Loss: 0.20208\n",
            "Epoch 275 | Train Acc: 86.68%\n",
            "Epoch 275 | Test Loss: 0.03613\n",
            "Epoch 275 | Test Acc: 98.66%\n",
            "--------------------------------------------------\n",
            "Epoch 280 | Train Loss: 0.19834\n",
            "Epoch 280 | Train Acc: 86.79%\n",
            "Epoch 280 | Test Loss: 0.02965\n",
            "Epoch 280 | Test Acc: 99.24%\n",
            "Test loss decreased from 0.03201 to 0.02965 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 285 | Train Loss: 0.20030\n",
            "Epoch 285 | Train Acc: 86.74%\n",
            "Epoch 285 | Test Loss: 0.03783\n",
            "Epoch 285 | Test Acc: 98.39%\n",
            "--------------------------------------------------\n",
            "Epoch 290 | Train Loss: 0.19724\n",
            "Epoch 290 | Train Acc: 87.05%\n",
            "Epoch 290 | Test Loss: 0.03602\n",
            "Epoch 290 | Test Acc: 98.50%\n",
            "--------------------------------------------------\n",
            "Epoch 295 | Train Loss: 0.19708\n",
            "Epoch 295 | Train Acc: 87.02%\n",
            "Epoch 295 | Test Loss: 0.02750\n",
            "Epoch 295 | Test Acc: 99.26%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = CNN1D().to(DEVICE)\n",
        "loss = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "history = Training(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    EPOCHS,\n",
        "    DEVICE,\n",
        "    loss,\n",
        "    optimizer,\n",
        "    print_every=5,\n",
        "    load_saved_model=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-6TDFQENOW8a"
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame(history)\n",
        "history_df.head()\n",
        "history_df.to_csv(\"CNN1D_history.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52cImhQDRdRh",
        "outputId": "026305a2-c2ef-43b0-9ecd-1642f4417faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train Loss: 0.53860\n",
            "Epoch 0 | Train Acc: 81.74%\n",
            "Epoch 0 | Test Loss: 0.45995\n",
            "Epoch 0 | Test Acc: 91.32%\n",
            "Test loss decreased to 0.45995 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 5 | Train Loss: 0.41638\n",
            "Epoch 5 | Train Acc: 92.53%\n",
            "Epoch 5 | Test Loss: 0.40598\n",
            "Epoch 5 | Test Acc: 92.80%\n",
            "Test loss decreased from 0.41930 to 0.40598 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 10 | Train Loss: 0.35899\n",
            "Epoch 10 | Train Acc: 93.45%\n",
            "Epoch 10 | Test Loss: 0.35025\n",
            "Epoch 10 | Test Acc: 93.65%\n",
            "Test loss decreased from 0.36691 to 0.35025 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 15 | Train Loss: 0.30708\n",
            "Epoch 15 | Train Acc: 94.12%\n",
            "Epoch 15 | Test Loss: 0.29761\n",
            "Epoch 15 | Test Acc: 94.38%\n",
            "Test loss decreased from 0.31056 to 0.29761 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 20 | Train Loss: 0.26040\n",
            "Epoch 20 | Train Acc: 94.45%\n",
            "Epoch 20 | Test Loss: 0.25159\n",
            "Epoch 20 | Test Acc: 95.08%\n",
            "Test loss decreased from 0.26781 to 0.25159 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 25 | Train Loss: 0.21972\n",
            "Epoch 25 | Train Acc: 95.24%\n",
            "Epoch 25 | Test Loss: 0.21068\n",
            "Epoch 25 | Test Acc: 95.54%\n",
            "Test loss decreased from 0.21916 to 0.21068 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 30 | Train Loss: 0.18855\n",
            "Epoch 30 | Train Acc: 95.68%\n",
            "Epoch 30 | Test Loss: 0.18297\n",
            "Epoch 30 | Test Acc: 95.55%\n",
            "Test loss decreased from 0.18778 to 0.18297 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 35 | Train Loss: 0.16406\n",
            "Epoch 35 | Train Acc: 95.83%\n",
            "Epoch 35 | Test Loss: 0.15637\n",
            "Epoch 35 | Test Acc: 96.35%\n",
            "Test loss decreased from 0.16012 to 0.15637 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 40 | Train Loss: 0.14711\n",
            "Epoch 40 | Train Acc: 96.07%\n",
            "Epoch 40 | Test Loss: 0.14275\n",
            "Epoch 40 | Test Acc: 95.90%\n",
            "--------------------------------------------------\n",
            "Epoch 45 | Train Loss: 0.12756\n",
            "Epoch 45 | Train Acc: 96.54%\n",
            "Epoch 45 | Test Loss: 0.12378\n",
            "Epoch 45 | Test Acc: 96.71%\n",
            "--------------------------------------------------\n",
            "Epoch 50 | Train Loss: 0.10850\n",
            "Epoch 50 | Train Acc: 97.08%\n",
            "Epoch 50 | Test Loss: 0.10687\n",
            "Epoch 50 | Test Acc: 96.83%\n",
            "--------------------------------------------------\n",
            "Epoch 55 | Train Loss: 0.10179\n",
            "Epoch 55 | Train Acc: 97.21%\n",
            "Epoch 55 | Test Loss: 0.10382\n",
            "Epoch 55 | Test Acc: 96.96%\n",
            "--------------------------------------------------\n",
            "Epoch 60 | Train Loss: 0.09079\n",
            "Epoch 60 | Train Acc: 97.61%\n",
            "Epoch 60 | Test Loss: 0.08542\n",
            "Epoch 60 | Test Acc: 97.80%\n",
            "Test loss decreased from 0.08770 to 0.08542 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 65 | Train Loss: 0.08379\n",
            "Epoch 65 | Train Acc: 97.71%\n",
            "Epoch 65 | Test Loss: 0.07827\n",
            "Epoch 65 | Test Acc: 97.97%\n",
            "Test loss decreased from 0.08306 to 0.07827 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 70 | Train Loss: 0.08803\n",
            "Epoch 70 | Train Acc: 97.06%\n",
            "Epoch 70 | Test Loss: 0.08069\n",
            "Epoch 70 | Test Acc: 97.76%\n",
            "--------------------------------------------------\n",
            "Epoch 75 | Train Loss: 0.07505\n",
            "Epoch 75 | Train Acc: 98.01%\n",
            "Epoch 75 | Test Loss: 0.07305\n",
            "Epoch 75 | Test Acc: 98.41%\n",
            "--------------------------------------------------\n",
            "Epoch 80 | Train Loss: 0.07358\n",
            "Epoch 80 | Train Acc: 98.09%\n",
            "Epoch 80 | Test Loss: 0.07562\n",
            "Epoch 80 | Test Acc: 98.08%\n",
            "--------------------------------------------------\n",
            "Epoch 85 | Train Loss: 0.07038\n",
            "Epoch 85 | Train Acc: 98.19%\n",
            "Epoch 85 | Test Loss: 0.06730\n",
            "Epoch 85 | Test Acc: 98.52%\n",
            "--------------------------------------------------\n",
            "Epoch 90 | Train Loss: 0.06721\n",
            "Epoch 90 | Train Acc: 98.14%\n",
            "Epoch 90 | Test Loss: 0.06171\n",
            "Epoch 90 | Test Acc: 98.48%\n",
            "Test loss decreased from 0.06560 to 0.06171 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 95 | Train Loss: 0.06314\n",
            "Epoch 95 | Train Acc: 98.46%\n",
            "Epoch 95 | Test Loss: 0.06066\n",
            "Epoch 95 | Test Acc: 98.38%\n",
            "--------------------------------------------------\n",
            "Epoch 100 | Train Loss: 0.06548\n",
            "Epoch 100 | Train Acc: 98.25%\n",
            "Epoch 100 | Test Loss: 0.05733\n",
            "Epoch 100 | Test Acc: 98.83%\n",
            "--------------------------------------------------\n",
            "Epoch 105 | Train Loss: 0.05809\n",
            "Epoch 105 | Train Acc: 98.57%\n",
            "Epoch 105 | Test Loss: 0.05451\n",
            "Epoch 105 | Test Acc: 98.58%\n",
            "--------------------------------------------------\n",
            "Epoch 110 | Train Loss: 0.05934\n",
            "Epoch 110 | Train Acc: 98.41%\n",
            "Epoch 110 | Test Loss: 0.05800\n",
            "Epoch 110 | Test Acc: 98.21%\n",
            "--------------------------------------------------\n",
            "Epoch 115 | Train Loss: 0.05629\n",
            "Epoch 115 | Train Acc: 98.59%\n",
            "Epoch 115 | Test Loss: 0.05139\n",
            "Epoch 115 | Test Acc: 98.95%\n",
            "--------------------------------------------------\n",
            "Epoch 120 | Train Loss: 0.05334\n",
            "Epoch 120 | Train Acc: 98.67%\n",
            "Epoch 120 | Test Loss: 0.04899\n",
            "Epoch 120 | Test Acc: 99.03%\n",
            "--------------------------------------------------\n",
            "Epoch 125 | Train Loss: 0.05130\n",
            "Epoch 125 | Train Acc: 98.80%\n",
            "Epoch 125 | Test Loss: 0.06280\n",
            "Epoch 125 | Test Acc: 98.61%\n",
            "--------------------------------------------------\n",
            "Epoch 130 | Train Loss: 0.04605\n",
            "Epoch 130 | Train Acc: 99.03%\n",
            "Epoch 130 | Test Loss: 0.04625\n",
            "Epoch 130 | Test Acc: 99.07%\n",
            "--------------------------------------------------\n",
            "Epoch 135 | Train Loss: 0.05426\n",
            "Epoch 135 | Train Acc: 98.60%\n",
            "Epoch 135 | Test Loss: 0.05706\n",
            "Epoch 135 | Test Acc: 98.24%\n",
            "--------------------------------------------------\n",
            "Epoch 140 | Train Loss: 0.04459\n",
            "Epoch 140 | Train Acc: 99.10%\n",
            "Epoch 140 | Test Loss: 0.04396\n",
            "Epoch 140 | Test Acc: 99.12%\n",
            "Test loss decreased from 0.04462 to 0.04396 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 145 | Train Loss: 0.05197\n",
            "Epoch 145 | Train Acc: 98.85%\n",
            "Epoch 145 | Test Loss: 0.04528\n",
            "Epoch 145 | Test Acc: 99.07%\n",
            "--------------------------------------------------\n",
            "Epoch 150 | Train Loss: 0.04723\n",
            "Epoch 150 | Train Acc: 98.99%\n",
            "Epoch 150 | Test Loss: 0.04533\n",
            "Epoch 150 | Test Acc: 99.03%\n",
            "--------------------------------------------------\n",
            "Epoch 155 | Train Loss: 0.04557\n",
            "Epoch 155 | Train Acc: 99.06%\n",
            "Epoch 155 | Test Loss: 0.06345\n",
            "Epoch 155 | Test Acc: 98.36%\n",
            "--------------------------------------------------\n",
            "Epoch 160 | Train Loss: 0.04446\n",
            "Epoch 160 | Train Acc: 99.05%\n",
            "Epoch 160 | Test Loss: 0.04690\n",
            "Epoch 160 | Test Acc: 98.81%\n",
            "--------------------------------------------------\n",
            "Epoch 165 | Train Loss: 0.04334\n",
            "Epoch 165 | Train Acc: 99.11%\n",
            "Epoch 165 | Test Loss: 0.04207\n",
            "Epoch 165 | Test Acc: 99.14%\n",
            "Test loss decreased from 0.04275 to 0.04207 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 170 | Train Loss: 0.04182\n",
            "Epoch 170 | Train Acc: 99.15%\n",
            "Epoch 170 | Test Loss: 0.04183\n",
            "Epoch 170 | Test Acc: 99.12%\n",
            "--------------------------------------------------\n",
            "Epoch 175 | Train Loss: 0.04195\n",
            "Epoch 175 | Train Acc: 99.13%\n",
            "Epoch 175 | Test Loss: 0.04047\n",
            "Epoch 175 | Test Acc: 99.17%\n",
            "Test loss decreased from 0.04056 to 0.04047 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 180 | Train Loss: 0.04381\n",
            "Epoch 180 | Train Acc: 98.99%\n",
            "Epoch 180 | Test Loss: 0.04137\n",
            "Epoch 180 | Test Acc: 99.14%\n",
            "--------------------------------------------------\n",
            "Epoch 185 | Train Loss: 0.03908\n",
            "Epoch 185 | Train Acc: 99.18%\n",
            "Epoch 185 | Test Loss: 0.03892\n",
            "Epoch 185 | Test Acc: 99.18%\n",
            "Test loss decreased from 0.03906 to 0.03892 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 190 | Train Loss: 0.03927\n",
            "Epoch 190 | Train Acc: 99.17%\n",
            "Epoch 190 | Test Loss: 0.03889\n",
            "Epoch 190 | Test Acc: 99.18%\n",
            "--------------------------------------------------\n",
            "Epoch 195 | Train Loss: 0.04125\n",
            "Epoch 195 | Train Acc: 99.06%\n",
            "Epoch 195 | Test Loss: 0.04060\n",
            "Epoch 195 | Test Acc: 99.05%\n",
            "--------------------------------------------------\n",
            "Epoch 200 | Train Loss: 0.03838\n",
            "Epoch 200 | Train Acc: 99.17%\n",
            "Epoch 200 | Test Loss: 0.03769\n",
            "Epoch 200 | Test Acc: 99.19%\n",
            "Test loss decreased from 0.03854 to 0.03769 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 205 | Train Loss: 0.04623\n",
            "Epoch 205 | Train Acc: 98.80%\n",
            "Epoch 205 | Test Loss: 0.04431\n",
            "Epoch 205 | Test Acc: 98.81%\n",
            "--------------------------------------------------\n",
            "Epoch 210 | Train Loss: 0.03675\n",
            "Epoch 210 | Train Acc: 99.19%\n",
            "Epoch 210 | Test Loss: 0.03705\n",
            "Epoch 210 | Test Acc: 99.19%\n",
            "--------------------------------------------------\n",
            "Epoch 215 | Train Loss: 0.04132\n",
            "Epoch 215 | Train Acc: 99.02%\n",
            "Epoch 215 | Test Loss: 0.03788\n",
            "Epoch 215 | Test Acc: 99.13%\n",
            "--------------------------------------------------\n",
            "Epoch 220 | Train Loss: 0.03684\n",
            "Epoch 220 | Train Acc: 99.16%\n",
            "Epoch 220 | Test Loss: 0.04019\n",
            "Epoch 220 | Test Acc: 99.10%\n",
            "--------------------------------------------------\n",
            "Epoch 225 | Train Loss: 0.04427\n",
            "Epoch 225 | Train Acc: 98.85%\n",
            "Epoch 225 | Test Loss: 0.03587\n",
            "Epoch 225 | Test Acc: 99.18%\n",
            "--------------------------------------------------\n",
            "Epoch 230 | Train Loss: 0.03368\n",
            "Epoch 230 | Train Acc: 99.22%\n",
            "Epoch 230 | Test Loss: 0.03487\n",
            "Epoch 230 | Test Acc: 99.18%\n",
            "--------------------------------------------------\n",
            "Epoch 235 | Train Loss: 0.03498\n",
            "Epoch 235 | Train Acc: 99.18%\n",
            "Epoch 235 | Test Loss: 0.03640\n",
            "Epoch 235 | Test Acc: 99.14%\n",
            "--------------------------------------------------\n",
            "Epoch 240 | Train Loss: 0.03731\n",
            "Epoch 240 | Train Acc: 99.05%\n",
            "Epoch 240 | Test Loss: 0.04859\n",
            "Epoch 240 | Test Acc: 98.43%\n",
            "--------------------------------------------------\n",
            "Epoch 245 | Train Loss: 0.03461\n",
            "Epoch 245 | Train Acc: 99.17%\n",
            "Epoch 245 | Test Loss: 0.03288\n",
            "Epoch 245 | Test Acc: 99.21%\n",
            "--------------------------------------------------\n",
            "Epoch 250 | Train Loss: 0.03149\n",
            "Epoch 250 | Train Acc: 99.23%\n",
            "Epoch 250 | Test Loss: 0.03119\n",
            "Epoch 250 | Test Acc: 99.23%\n",
            "Test loss decreased from 0.03124 to 0.03119 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 255 | Train Loss: 0.03222\n",
            "Epoch 255 | Train Acc: 99.19%\n",
            "Epoch 255 | Test Loss: 0.03152\n",
            "Epoch 255 | Test Acc: 99.24%\n",
            "--------------------------------------------------\n",
            "Epoch 260 | Train Loss: 0.03344\n",
            "Epoch 260 | Train Acc: 99.17%\n",
            "Epoch 260 | Test Loss: 0.03197\n",
            "Epoch 260 | Test Acc: 99.23%\n",
            "--------------------------------------------------\n",
            "Epoch 265 | Train Loss: 0.02919\n",
            "Epoch 265 | Train Acc: 99.24%\n",
            "Epoch 265 | Test Loss: 0.02907\n",
            "Epoch 265 | Test Acc: 99.26%\n",
            "--------------------------------------------------\n",
            "Epoch 270 | Train Loss: 0.04201\n",
            "Epoch 270 | Train Acc: 99.01%\n",
            "Epoch 270 | Test Loss: 0.03031\n",
            "Epoch 270 | Test Acc: 99.21%\n",
            "--------------------------------------------------\n",
            "Epoch 275 | Train Loss: 0.03118\n",
            "Epoch 275 | Train Acc: 99.18%\n",
            "Epoch 275 | Test Loss: 0.02844\n",
            "Epoch 275 | Test Acc: 99.23%\n",
            "--------------------------------------------------\n",
            "Epoch 280 | Train Loss: 0.02793\n",
            "Epoch 280 | Train Acc: 99.25%\n",
            "Epoch 280 | Test Loss: 0.02644\n",
            "Epoch 280 | Test Acc: 99.30%\n",
            "Test loss decreased from 0.02759 to 0.02644 saving new best model\n",
            "--------------------------------------------------\n",
            "Epoch 285 | Train Loss: 0.03628\n",
            "Epoch 285 | Train Acc: 98.99%\n",
            "Epoch 285 | Test Loss: 0.02967\n",
            "Epoch 285 | Test Acc: 99.22%\n",
            "--------------------------------------------------\n",
            "Epoch 290 | Train Loss: 0.02766\n",
            "Epoch 290 | Train Acc: 99.24%\n",
            "Epoch 290 | Test Loss: 0.02821\n",
            "Epoch 290 | Test Acc: 99.17%\n",
            "--------------------------------------------------\n",
            "Epoch 295 | Train Loss: 0.02785\n",
            "Epoch 295 | Train Acc: 99.21%\n",
            "Epoch 295 | Test Loss: 0.02492\n",
            "Epoch 295 | Test Acc: 99.31%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# LSTM\n",
        "INPUT_SIZE = train_loader.dataset[0][0].shape[0]\n",
        "HIDDEN_STATE = 64\n",
        "NUM_LAYERS = 4\n",
        "NUM_CLASSES = 1 #* binary classification\n",
        "model = BILSTM(INPUT_SIZE, HIDDEN_STATE, NUM_LAYERS, NUM_CLASSES, bidirection=True).to(DEVICE)\n",
        "loss = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "history = Training(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    EPOCHS,\n",
        "    DEVICE,\n",
        "    loss,\n",
        "    optimizer,\n",
        "    print_every=5,\n",
        "    load_saved_model=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h-TzNwV-Rlpx"
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame(history)\n",
        "history_df.head()\n",
        "history_df.to_csv(\"BILSTM_history.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}